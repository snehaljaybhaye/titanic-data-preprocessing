{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeebd280",
   "metadata": {},
   "source": [
    "\n",
    "# Titanic Dataset Preprocessing ðŸ§¹ðŸš¢\n",
    "\n",
    "This notebook demonstrates essential data preprocessing techniques on the Titanic dataset, including missing value handling, encoding, scaling, and outlier detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f0766",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Task 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307eba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Load Titanic dataset from seaborn or local file\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5f584c",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Task 2: Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Drop columns with more than 50% missing values\n",
    "threshold = len(df) * 0.5\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Fill numerical columns with median\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa51149",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Task 3: Remove Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check and remove duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Removed {duplicates} duplicate rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9864d3bd",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Task 4: Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32846fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert boolean columns to int\n",
    "df['alone'] = df['alone'].astype(int)\n",
    "df['adult_male'] = df['adult_male'].astype(int)\n",
    "\n",
    "# One-hot encoding for categorical columns\n",
    "df = pd.get_dummies(df, columns=['sex', 'embarked', 'class', 'who', 'deck', 'embark_town'], drop_first=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff80fb6",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Task 5: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa894a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize and standardize numerical columns\n",
    "scaler_minmax = MinMaxScaler()\n",
    "scaler_std = StandardScaler()\n",
    "\n",
    "num_cols = ['age', 'fare', 'parch', 'sibsp']\n",
    "\n",
    "df_minmax = df.copy()\n",
    "df_minmax[num_cols] = scaler_minmax.fit_transform(df_minmax[num_cols])\n",
    "\n",
    "df_std = df.copy()\n",
    "df_std[num_cols] = scaler_std.fit_transform(df_std[num_cols])\n",
    "\n",
    "# Display scaled data\n",
    "df_minmax.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef22260",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Task 6: Outlier Detection Using IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23698d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# IQR method to remove outliers\n",
    "for col in ['age', 'fare']:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdad8b53",
   "metadata": {},
   "source": [
    "## âœ… Final Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"cleaned_titanic.csv\", index=False)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
